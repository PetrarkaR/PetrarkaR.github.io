---
title: Metalearning
date: 2025-11-02 00:20:02 +0100
categories: [thoughts]
published: true
layout: post
---

# Learning about learning

Been divesting a lot of my time recently to learn about learning. Not quite a simple process as it may seem. Although learning about learning is just a theoretical process, there is no work you can put into it, you just learn about learning. That's it. You just read and hope to apply in the next session of your studies. 

So I wanted to draw a parallel about how computers "learn" and interpret things, since they can only understand things as models, what the fuck does that even mean? What is a model? A model, similar to a mental model serves as kind of a heuristic. A quote by a psychologist who's name I cannot remember now goes something like

```
All models are wrong, but some are useful
```
Is quite accurate in this context. Models can be thought of as interpolations of data, just filling in the gaps based on a calculation. 

It's quite different from how humans learn and interpret data. Humans often times need to understand why is something. They cannot just "remember" everything like a computer can. Our brain has limited storage (well a computer does too, but I can see it "remembering" 10000 facts about birds as opposed to me). So for a human to learn and understand things, they also compile it into a model, but the model is in relation to what they know previously (if that is a possibility, if the topic is new, there needs to be an entirely new model that will serve as a base for future learning and the fundamentals must be well understood). 

What's also interesting about humans and computers is that computers always need to come to a conclusion. There always needs to be that finishing layer at the end of the learning that tells us what the answer is to our problem or what the output function is. With humans that is not the case, you can for example learn something without any need to draw any sort of resolution out of it. You can just know it for the fun of it. 

---

But how do computers even "learn" (using the word learn very liberally here, I think the more proper term would be "calculate" or "estimate")? They learn when we pass some input data through some intermediate layers of neurons with a set of modifiable weights and in the end we get something at the output! If the error rate is large we go back through a feedback loop and the process continues, if the error rate is smaller then we are doing good. This goes on for a few epochs until we learn good from bad. Now... how do humans learn... well a human also gets some input data and it... uhm??? What happens next, you read something and what happens with it? Some wheels and cogs spin and magically you understand the whole thing? I'm not really sure. Humans are very complex. What does it even mean to understand something? That's what I set out to do. To learn how to learn, to understand the whole biochemical process, from the reading to the firing of the neurons in the brain. I wanna get it down to a science. Methodically and mathematically obliterate everything. Since that's what it's all about for me, the goal is to make myself be a like a computer (since you previously saw how simple they are, we got the whole learning process into 2 sentences). 

---

The goal is to be a computer. An automaton.